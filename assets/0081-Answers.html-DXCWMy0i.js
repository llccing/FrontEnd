import{_ as a,c as t,a as s,o as n}from"./app-DxUSmTbc.js";const o={};function i(r,e){return n(),t("div",null,[...e[0]||(e[0]=[s('<h1 id="q81" tabindex="-1"><a class="header-anchor" href="#q81"><span>Q81</span></a></h1><p><strong>Answer:</strong> C</p><p>decoupled = SQS Launch template = AMI Launch configuration = EC2</p><hr><p>This design follows the best practices for loosely coupled and scalable architecture. By using SQS, the jobs are durably stored in the queue, ensuring they are not lost. The processor application is stateless, which aligns with the design requirement. The AMI allows for consistent deployment of the application. The launch template and ASG facilitate the dynamic scaling of the application based on the number of items in the SQS, ensuring parallel processing of jobs.</p><p>Options A and D suggest using SNS, which is a publish/subscribe messaging service and may not provide the durability required for job storage.</p><p>Option B suggests using network usage as a scaling metric, which may not be directly related to the number of jobs to be processed. The number of items in the SQS provides a more accurate metric for scaling based on the workload.</p><h2 id="q82" tabindex="-1"><a class="header-anchor" href="#q82"><span>Q82</span></a></h2><p><strong>Answer:</strong> B</p><p>B AWS Config has a managed rule named acm-certificate-expiration-check to check for expiring certificates (configurable number of days)</p><p>https://repost.aws/knowledge-center/acm-certificate-expiration</p><h2 id="q83" tabindex="-1"><a class="header-anchor" href="#q83"><span>Q83</span></a></h2><p><strong>Answer:</strong> C</p><p>The key reasons are:</p><p>CloudFront can cache static content close to European users using edge locations, improving site performance. The custom origin feature allows seamlessly integrating the CloudFront CDN with existing on-premises servers. No changes are needed to the site backend or servers. CloudFront just acts as a globally distributed cache. This can be set up very quickly, meeting the launch deadline. Other options like migrating to EC2 or S3 would require more time and changes. CloudFront is an easier lift. Route 53 geoproximity routing alone would not improve performance much without a CDN.</p><h2 id="q84" tabindex="-1"><a class="header-anchor" href="#q84"><span>Q84</span></a></h2><p><strong>Answer:</strong> B</p><p>Option B, would indeed be the most cost-effective solution. Reserved Instances provide cost savings for instances that run consistently, such as the production environment in this case, while On-Demand Instances offer flexibility and are suitable for instances with variable usage patterns like the development and test environments. This combination ensures cost optimization based on the specific requirements and usage patterns described in the question.</p><h2 id="q85" tabindex="-1"><a class="header-anchor" href="#q85"><span>Q85</span></a></h2><p><strong>Answer:</strong> A</p><p>You can use S3 Object Lock to store objects using a write-once-read-many (WORM) model. Object Lock can help prevent objects from being deleted or overwritten for a fixed amount of time or indefinitely. You can use S3 Object Lock to meet regulatory requirements that require WORM storage, or add an extra layer of protection against object changes and deletion. Versioning is required and automatically activated as Object Lock is enabled. https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock-overview.html</p><h2 id="q86" tabindex="-1"><a class="header-anchor" href="#q86"><span>Q86</span></a></h2><p><strong>Answer:</strong> A</p><p>Secrets Manager enables you to replace hardcoded credentials in your code, including passwords, with an API call to Secrets Manager to retrieve the secret programmatically. This helps ensure the secret can&#39;t be compromised by someone examining your code, because the secret no longer exists in the code. Also, you can configure Secrets Manager to automatically rotate the secret for you according to a specified schedule. This enables you to replace long-term secrets with short-term ones, significantly reducing the risk of compromise. https://docs.aws.amazon.com/secretsmanager/latest/userguide/intro.html</p><hr><p>B. SSM OpsCenter is primarily used for managing and resolving operational issues. It is not designed to securely store and manage credentials like AWS Secrets Manager.</p><p>C. Storing credentials in an S3 bucket may provide some level of security, but it lacks the additional features and security controls offered by AWS Secrets Manager.</p><p>D. While using KMS for encryption is a good practice, managing credentials directly on the web server file system can introduce complexities and potential security risks. It can be challenging to securely manage and rotate credentials across multiple web servers, especially when considering scalability and automation.</p><p>In summary, option A is the recommended solution as it leverages AWS Secrets Manager, which is purpose-built for securely storing and managing secrets, and provides the necessary IAM permissions to allow the web servers to access the credentials securely.</p><h2 id="q87" tabindex="-1"><a class="header-anchor" href="#q87"><span>Q87</span></a></h2><p><strong>Answer:</strong> D</p><p>Ans D - as excellently explained by SaurabhTiwari1 (9 mth ago) &quot;The original question was about handling a situation where the database is unavailable due to an upgrade, not a failover situation. During a database upgrade, the database instance is not available, and RDS Proxy would not be able to connect to a new database instance because there isn’t one.&quot;</p><p>In this specific scenario, using Amazon SQS as described in option D provides a buffer for the incoming data during the period when the database is unavailable. This ensures that no data is lost, and it can be written to the database once the upgrade is complete.</p><h2 id="q88" tabindex="-1"><a class="header-anchor" href="#q88"><span>Q88</span></a></h2><p><strong>Answer:</strong> A</p><p>&quot;Typically, you configure buckets to be Requester Pays buckets when you want to share data but not incur charges associated with others accessing the data. For example, you might use Requester Pays buckets when making available large datasets, such as zip code directories, reference data, geospatial information, or web crawling data.&quot; https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysBuckets.html</p><hr><p>Option A. When you use S3 Cross-Region Replication (CRR), you will incur data transfer costs. These costs include a fee for transferring data between regions, which is approximately $0.02 per GB.</p><hr><p>Why Not the Other Options? B. S3 Cross-Region Replication: Cross-Region Replication (CRR) copies data between S3 buckets in different AWS Regions but incurs data transfer costs for replication, which does not minimize costs for the survey company. It is also unnecessary if the marketing firm can directly access the bucket. C. Cross-Account Access: Granting cross-account access allows the marketing firm to read data directly, but the data transfer costs would still be borne by the survey company, which contradicts the goal of minimizing the company’s costs. D. S3 Intelligent-Tiering: S3 Intelligent-Tiering optimizes storage costs for infrequently accessed data but does not address the need to minimize data transfer costs during sharing. Syncing the bucket to the marketing firm’s bucket would also incur transfer costs.</p><h2 id="q89" tabindex="-1"><a class="header-anchor" href="#q89"><span>Q89</span></a></h2><p><strong>Answer:</strong> A</p><p>Same as Question #44</p><hr><p>Enable the versioning to ensure restoration in case of accidental deletion and MFA Delete for double verification before deletion.</p><h2 id="q90" tabindex="-1"><a class="header-anchor" href="#q90"><span>Q90</span></a></h2><p><strong>Answer:</strong> B</p><p>Just read from read replica. A: This will make it HA but won&#39;t solve any problems C: We want an AWS solution not change the development team&#39;s ways of working D: Elasticache is cache of read queries when data doesn&#39;t change. It&#39;s useless for finding new data.</p>',48)])])}const l=a(o,[["render",i]]),d=JSON.parse('{"path":"/AWS/SAA/02Examtopics/Questions/0081-Answers.html","title":"Q81","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/SAA/02Examtopics/Questions/0081-Answers.md"}');export{l as comp,d as data};
