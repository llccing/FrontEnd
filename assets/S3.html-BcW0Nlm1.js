import{_ as a,c as t,a as o,o as n}from"./app-DxUSmTbc.js";const s={};function i(r,e){return n(),t("div",null,[...e[0]||(e[0]=[o('<h2 id="s3" tabindex="-1"><a class="header-anchor" href="#s3"><span>S3</span></a></h2><p>Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industry-leading scalability, data availability, security, and performance. Customers of all sizes and industries can use Amazon S3 to store and protect any amount of data for a range of use cases, such as data lakes, websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides management features so that you can optimize, organize, and configure access to your data to meet your specific business, organizational, and compliance requirements.</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html" target="_blank" rel="noopener noreferrer">more about S3</a></p><h3 id="s3-transfer-acceleration" tabindex="-1"><a class="header-anchor" href="#s3-transfer-acceleration"><span>S3 Transfer Acceleration</span></a></h3><p>Amazon S3 Transfer Acceleration can speed up content transfers to and from Amazon S3 by as much as 50-500% for long-distance transfer of larger objects. Customers who have either web or mobile applications with widespread users or applications hosted far away from their S3 bucket can experience long and variable upload and download speeds over the Internet. S3 Transfer Acceleration (S3TA) reduces the variability in Internet routing, congestion and speeds that can affect transfers, and logically shortens the distance to S3 for remote applications. S3TA improves transfer performance by routing traffic through Amazon CloudFront’s globally distributed Edge Locations and over AWS backbone networks, and by using network protocol optimizations. You can turn on S3TA with a few clicks in the S3 console, and test its benefits from your location with a speed comparison tool. With S3TA, you pay only for transfers that are accelerated.</p><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/transfer-acceleration.html" target="_blank" rel="noopener noreferrer">more about S3 Transfer Acceleration</a></p><h3 id="bucket" tabindex="-1"><a class="header-anchor" href="#bucket"><span>Bucket</span></a></h3><p>要向 Amazon S3 上传数据（照片、视频、文档等），您必须首先在其中一个 AWS 区域 中创建 S3 存储桶。存储桶是 Amazon S3 中用于存储对象的容器。您可以在存储桶中存储任意数量的对象，并且账户中最多可以有 100 个存储桶。要查看存储桶利用率、存储桶配额或请求增加配额，请访问服务配额控制台。</p><p>Amazon S3 支持全局存储桶，这意味着每个存储桶名称在分区内的所有AWS 区域中所有AWS 账户内都必须是唯一的。分区是一组区域。AWS 目前有三个分区：aws（标准区域）、aws-cn（中国区域）和 aws-us-gov（AWS GovCloud (US)）。</p><p><a href="https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/UsingBucket.html" target="_blank" rel="noopener noreferrer">more about Bucket</a></p><h3 id="s3-file-gateway" tabindex="-1"><a class="header-anchor" href="#s3-file-gateway"><span>S3 File Gateway</span></a></h3><p>Store and access objects in Amazon S3 from <strong>NFS</strong> or <strong>SMB</strong> file data with local caching</p><p><a href="https://aws.amazon.com/storagegateway/file/s3/" target="_blank" rel="noopener noreferrer">AWS Storage Gateway - S3 File Gateway</a></p><p><a href="https://aws.amazon.com/compare/the-difference-between-nfs-smb/" target="_blank" rel="noopener noreferrer">The Difference Between NFS and SMB</a> Network File System (NFS) and Server Message Block (SMB) are file access storage protocols or rules for efficient file sharing over a network. The ability to communicate, collaborate, and share files effectively is essential for any organization’s day-to-day operations. With NFS, a user (or client device) can connect to a network server and access files on the server. It has rules that allow multiple users to share the same file without data conflicts. Similarly, SMB also allows users to read files on the server. However, it offers more flexibility, so clients can share files with each other as well. Clients can use SMB to establish connections with any other networked devices—like printers or file servers. The client can then access the device’s files as if it were local to the client.</p><h3 id="s3-intelligent-tiering" tabindex="-1"><a class="header-anchor" href="#s3-intelligent-tiering"><span>S3 Intelligent-Tiering</span></a></h3><h4 id="什么是-s3-intelligent-tiering" tabindex="-1"><a class="header-anchor" href="#什么是-s3-intelligent-tiering"><span>什么是 S3 Intelligent-Tiering？</span></a></h4><p>S3 Intelligent-Tiering 是首个云存储，它可以根据访问频率自动将数据移至最经济实惠的访问层，从而自动在细粒度对象级别降低您的存储成本，并且不会产生性能影响、取回费用或运营开销。S3 Intelligent-Tiering 可以为频繁、不频繁和归档即时访问层中的频繁、不频繁以及很少访问的数据提供毫秒级延迟和提高吞吐量性能。每月只需支付少量的对象监控和自动化费用，S3 Intelligent-Tiering 即可监控访问模式并将对象从一个访问层自动移动到另一个访问层。S3 Intelligent-Tiering 没有任何取回费用，因此在访问模式发生变化时存储账单不会意外增加。</p><p>现在，您可以通过虚拟方式将 S3 Intelligent-Tiering 用作任何工作负载（尤其是数据湖、数据分析、机器学习、新应用程序和用户生成的内容）的默认存储类。</p><h3 id="standard-infrequent-access-s3-standard-ia" tabindex="-1"><a class="header-anchor" href="#standard-infrequent-access-s3-standard-ia"><span>Standard-Infrequent Access (S3 Standard-IA)</span></a></h3><p>S3 Standard-Infrequent Access (S3 Standard-IA) 是一种 Amazon S3 存储类，用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 提供了 Amazon S3 Standard 存储类的高持久性、高吞吐量和低延迟，每 GB 存储价格和每 GB 取回费用都比较低。成本较低且性能出色使得 S3 Standard-IA 成为长期存储和备份的理想选择，也非常适用于灾难恢复的数据存储。S3 Standard-IA 存储类是在对象级别进行设置的，并且可以与 S3 Standard 或 S3 One Zone-IA 存储类存在于同一个存储桶中，从而让您可以使用 S3 生命周期策略在存储类之间自动转移对象，而无需更改任何应用程序。</p><h4 id="why-choose-s3-ia" tabindex="-1"><a class="header-anchor" href="#why-choose-s3-ia"><span>why choose s3 ia</span></a></h4><p>S3 Standard-IA 适用于不常访问但在需要时要求快速访问的数据。S3 Standard-IA 非常适合长期文件存储、较旧的同步和共享存储以及其他老化数据。</p><h3 id="common-questions" tabindex="-1"><a class="header-anchor" href="#common-questions"><span>Common Questions</span></a></h3><p>AWS Regions Q: Where is my data stored?</p><p>您在创建 Amazon S3 存储桶时指定一个 AWS 区域。对于 S3 Standard、S3 Standard-IA、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类别，您的对象会自动存储在跨越至少三个可用区 (AZ) 的多个设备上。可用区之间相隔有意义的距离，通常是几公里，尽管它们都在 100 公里 (60 英里) 以内。存储在 S3 One Zone-IA 存储类别中的对象会在您选择的 AWS 区域内的单个可用区中冗余存储。对于 S3 on Outposts，您的数据存储在您本地的 Outpost 环境中，除非您手动选择将其转移到 AWS 区域。有关 Amazon S3 服务在 AWS 区域内可用性的详细信息，请参阅 AWS 区域服务列表。</p><p>Q: What is an AWS Region?</p><p>An AWS Region is a physical location around the world where AWS cluster data centers. Each group of logical data centers within a Region is know as an Availability Zone (AZ). Each AWS Region consists of a minimum of three, isolated, and physically separate AZs within a geographic area. Unlike other cloud providers, who often define a Region as a single data center, the multiple AZ design of every AWS Region offers advantages for customers. Each AZ has independent power, cooling, and physical security and is connected via redundant, ultra-low-latency networks.</p><p>Chinese version: AWS 区域是 AWS 集群数据中心的物理位置。每个区域内的逻辑数据中心组称为可用区 (AZ)。每个 AWS 区域至少包含三个独立、物理隔离的可用区。与将区域定义为单个数据中心的其他云提供商不同，每个 AWS 区域的多可用区设计为 AWS 客户提供了优势。每个可用区都有独立电源、冷却和物理安全，并通过冗余的超低延迟网络连接。</p><p>Q: What is an AWS Availability Zone (AZ)?</p><p>An Availability Zone (AZ) is one or more discrete data centers with redundant power, networking, and connectivity in an AWS Region. AZs give customers the ability to operate production applications and databases that are more highly available, fault tolerant, and scalable than would be possible from a single data center. All AZs in an AWS Region are interconnected with high-bandwidth, low-latency networking, over fully redundant, dedicated metro fiber providing high-throughput, low-latency networking between AZs.</p><p>Amazon S3 Standard, S3 Standard-Infrequent Access, S3 Intelligent-Tiering, S3 Glacier Instant Retrieval, S3 Glacier Flexible Retrieval, and S3 Glacier Deep Archive storage classes replicate data across a minimum of three AZs to protect against the loss of one entire AZ. This remains true in Regions where fewer than three AZs are publicly available. Objects stored in these storage classes are available for access from all of the AZs in an AWS Region.</p><p>The Amazon S3 One Zone-IA storage class replicates data within a single AZ. The data stored in S3 One Zone-IA is not resilient to the physical loss of an Availability Zone resulting from disasters, such as earthquakes, fires, and floods.</p><p>Chinese version: AWS 的可用区（AZ）是一个或多个独立的数据中心，具有冗余的电力、网络和连接，位于一个 AWS 区域内。可用区使客户能够运行生产应用程序和数据库，这些应用程序和数据库比单个数据中心更高可用性、更具容错性和可扩展性。一个 AWS 区域内的所有可用区通过高带宽、低延迟的网络互连，使用完全冗余的专用地铁光纤提供高吞吐量、低延迟的网络连接。</p><p>Amazon S3 Standard、S3 Standard-Infrequent Access、S3 Intelligent-Tiering、S3 Glacier Instant Retrieval、S3 Glacier Flexible Retrieval 和 S3 Glacier Deep Archive 存储类别将数据复制到至少三个可用区，以防止整个可用区丢失。在少于三个可用区公开的区域中，这一点仍然适用。这些存储类别中的对象可以从 AWS 区域内的所有可用区进行访问。</p><p>Amazon S3 One Zone-IA 存储类别在单个可用区内复制数据。存储在 S3 One Zone-IA 中的数据不具备应对地震、火灾和洪水等灾害导致的可用区物理损失的弹性。</p><h3 id="s3-object-lock" tabindex="-1"><a class="header-anchor" href="#s3-object-lock"><span>S3 Object Lock</span></a></h3><p><a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lock.html" target="_blank" rel="noopener noreferrer">S3 Object Lock</a></p><p>S3 Object Lock is a feature that allows you to store objects in Amazon S3 in a way that prevents them from being deleted or overwritten for a specified period of time. This feature is useful for scenarios where you need to ensure that objects are not deleted or modified accidentally, such as when storing sensitive data or important business documents.</p><p>S3 Object Lock provides two modes: Governance and Compliance.</p><p>In compliance mode, a protected object version can&#39;t be overwritten or deleted by any user, including the root user in your AWS account. When an object is locked in compliance mode, its retention mode can&#39;t be changed, and its retention period can&#39;t be shortened. Compliance mode helps ensure that an object version can&#39;t be overwritten or deleted for the duration of the retention period.</p><p>note: The only way to delete an object under the compliance mode before its retention date expires is to delete the associated AWS account.</p><p>In governance mode, users can&#39;t overwrite or delete an object version or alter its lock settings unless they have special permissions. With governance mode, you protect objects against being deleted by most users, but you can still grant some users permission to alter the retention settings or delete the objects if necessary. You can also use governance mode to test retention-period settings before creating a compliance-mode retention period.</p><h4 id="s3-object-lock-legal-hold" tabindex="-1"><a class="header-anchor" href="#s3-object-lock-legal-hold"><span>S3 Object Lock legal hold</span></a></h4><p>You can use Amazon S3 Batch Operations to perform large-scale batch operations on Amazon S3 objects. You can use the Object Lock legal hold operation to place a legal hold on an object version. Like setting a retention period, a legal hold prevents an object version from being overwritten or deleted. However, a legal hold doesn&#39;t have an associated retention period and remains in effect until it&#39;s removed.</p><p>https://docs.amazonaws.cn/en_us/AmazonS3/latest/userguide/batch-ops-legal-hold.html</p><h3 id="how-do-i-use-my-cloudfront-distribution-to-restrict-access-to-an-amazon-s3-bucket" tabindex="-1"><a class="header-anchor" href="#how-do-i-use-my-cloudfront-distribution-to-restrict-access-to-an-amazon-s3-bucket"><span>How do I use my CloudFront distribution to restrict access to an Amazon s3 bucket?</span></a></h3><p>Option 1 (Best practice): Create a CloudFront OAC Option 2: Create a legacy CloudFront OAI</p><h3 id="multipart-uploads" tabindex="-1"><a class="header-anchor" href="#multipart-uploads"><span>Multipart Uploads</span></a></h3><p>Multipart upload allows you to upload a single object to Amazon S3 as a set of parts. Each part is a contiguous portion of the object&#39;s data. You can upload these object parts independently, and in any order. For uploads, your updated AWS client automatically calculates a checksum of the object and sends it to Amazon S3 along with the size of the object as a part of the request. If transmission of any part fails, you can retransmit that part without affecting other parts. After all parts of your object are uploaded, Amazon S3 assembles them to create the object. It&#39;s a best practice to use multipart upload for objects that are 100 MB or larger instead of uploading them in a single operation.</p><p>Using multipart upload provides the following advantages:</p><ul><li><p>Improved throughput – You can upload parts in parallel to improve throughput.</p></li><li><p>Quick recovery from any network issues – Smaller part size minimizes the impact of restarting a failed upload due to a network error.</p></li><li><p>Pause and resume object uploads – You can upload object parts over time. After you initiate a multipart upload, there is no expiry; you must explicitly complete or stop the multipart upload.</p></li><li><p>Begin an upload before you know the final object size – You can upload an object as you create it.</p></li></ul><h3 id="s3-lifecycle" tabindex="-1"><a class="header-anchor" href="#s3-lifecycle"><span>S3 Lifecycle</span></a></h3><p>S3 Lifecycle helps you store objects cost effectively throughout their lifecycle by transitioning them to lower-cost storage classes, or, deleting expired objects on your behalf. To manage the lifecycle of your objects, create an S3 Lifecycle configuration for your bucket. An S3 Lifecycle configuration is a set of rules that define actions that Amazon S3 applies to a group of objects. There are two types of actions:</p><ul><li><p>Transition actions – These actions transition objects to a different storage class.</p></li><li><p>Expiration actions – These actions delete objects after a specified period of time.</p></li></ul><p>in my words, the transition is set a lifecycle policy to move objects to a lower cost storage class. and the expiration is set expiration time to delete objects.</p><p>https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html</p><h3 id="s3-glacier-instant-retrieval" tabindex="-1"><a class="header-anchor" href="#s3-glacier-instant-retrieval"><span>S3 Glacier Instant Retrieval</span></a></h3><p>Amazon S3 Glacier Instant Retrieval is an archive storage class that delivers the lowest-cost storage for long-lived data that is rarely accessed and requires retrieval in milliseconds. With S3 Glacier Instant Retrieval, you can <strong>save up to 68% on storage costs</strong> compared to using the <strong>S3 Standard-Infrequent Access (S3 Standard-IA) storage class</strong>, when your data is accessed once per quarter. S3 Glacier Instant Retrieval delivers the fastest access to archive storage, with the same throughput and milliseconds access as the S3 Standard and S3 Standard-IA storage classes. S3 Glacier Instant Retrieval is designed for 99.999999999% (11 nines) of data durability and 99.9% availability by redundantly storing data across multiple physically separated AWS Availability Zones. It is designed for rarely accessed data that still needs immediate access in performance-sensitive use cases like image hosting, online file-sharing applications, medical imaging and health records, news media assets, and genomics.</p><p>https://aws.amazon.com/s3/storage-classes/glacier/instant-retrieval/</p><h3 id="s3-cors" tabindex="-1"><a class="header-anchor" href="#s3-cors"><span>S3 CORS</span></a></h3><p>https://docs.aws.amazon.com/AmazonS3/latest/userguide/cors.html</p><p>Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. With CORS support, you can build rich client-side web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources.</p><h3 id="s3-presigned-upload" tabindex="-1"><a class="header-anchor" href="#s3-presigned-upload"><span>S3 PreSigned Upload</span></a></h3><p>You may use presigned URLs to allow someone to upload an object to your Amazon S3 bucket. Using a presigned URL will allow an upload without requiring another party to have AWS security credentials or permissions. A presigned URL is limited by the permissions of the user who creates it. That is, if you receive a presigned URL to upload an object, you can upload an object only if the creator of the URL has the necessary permissions to upload that object.</p><p>When someone uses the URL to upload an object, Amazon S3 creates the object in the specified bucket. If an object with the same key that is specified in the presigned URL already exists in the bucket, Amazon S3 replaces the existing object with the uploaded object. After upload, the bucket owner will own the object.</p><p>https://docs.aws.amazon.com/AmazonS3/latest/userguide/PresignedUrlUploadObject.html</p><h3 id="s3-event-notification" tabindex="-1"><a class="header-anchor" href="#s3-event-notification"><span>S3 Event Notification</span></a></h3><p>You can use the Amazon S3 Event Notifications feature to receive notifications when certain events happen in your S3 bucket. To enable notifications, add a notification configuration that identifies the events that you want Amazon S3 to publish. Make sure that it also identifies the destinations where you want Amazon S3 to send the notifications. You store this configuration in the notification subresource that&#39;s associated with a bucket. For more information, see Bucket configuration options. Amazon S3 provides an API for you to manage this subresource.</p>',68)])])}const l=a(s,[["render",i]]),d=JSON.parse('{"path":"/AWS/SAA/01Features/S3.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/SAA/01Features/S3.md"}');export{l as comp,d as data};
