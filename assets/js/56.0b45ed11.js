(window.webpackJsonp=window.webpackJsonp||[]).push([[56],{339:function(e,t,n){"use strict";n.r(t);var o=n(14),s=Object(o.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[e._v("24.A company wants to make a chatbot to help customers. The chatbot will help  solve technical problems without hurnan intervention.The company chose a  foundation model （FM） for the chatbot. The chatbot needs to produce responses  that adhere to company tone.Which solution meets these requirements?\nA.Set a low limit on the number of tokens the FM can produce.\nB.Use batch inferencing to process detailed responses.\nC.refine the prompt until the FM produces the desired responses.\nD.Define a higher number for the temperature parameter.")]),e._v(" "),t("p",[t("strong",[e._v("Correct answer: C. Refine the prompt until the FM produces the desired responses.")])]),e._v(" "),t("p",[e._v("To ensure the chatbot’s replies "),t("strong",[e._v("adhere to the company tone")]),e._v(", you need "),t("strong",[e._v("prompt engineering")]),e._v(" (and typically a fixed “system”/instruction prompt with style guidelines, do/don’t rules, examples, etc.). Refining the prompt is the direct way to guide a foundation model’s "),t("strong",[e._v("tone and response style")]),e._v(" without human intervention.")]),e._v(" "),t("p",[e._v("Why the others don’t meet the requirement:")]),e._v(" "),t("ul",[t("li",[t("strong",[e._v("A")]),e._v(" limits response length, not tone.")]),e._v(" "),t("li",[t("strong",[e._v("B")]),e._v(" batch inference is about throughput/cost, not tone control.")]),e._v(" "),t("li",[t("strong",[e._v("D")]),e._v(" higher temperature increases randomness/creativity, making tone "),t("strong",[e._v("less consistent")]),e._v(", not more.")])])])}),[],!1,null,null,null);t.default=s.exports}}]);