import{_ as a,c as t,a as s,o as n}from"./app-DxUSmTbc.js";const o={};function i(r,e){return n(),t("div",null,[...e[0]||(e[0]=[s('<h2 id="q71" tabindex="-1"><a class="header-anchor" href="#q71"><span>Q71</span></a></h2><p><strong>Answer:</strong> B</p><p>A - DynamoDB global tables provides multi-Region, and multi-active database, but it not valid &quot;in case of data corruption&quot;. In this case, you need a backup. This solutions isn&#39;t valid. <strong>B</strong> - Point in Time Recovery is designed as a continuous backup juts to recover it fast. It covers perfectly the RPO, and probably the RTO. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/PointInTimeRecovery.html C - A daily export will not cover the RPO of 15min. D - DynamoDB is serverless... so what are these EBS snapshots taken from???</p><h2 id="q72" tabindex="-1"><a class="header-anchor" href="#q72"><span>Q72</span></a></h2><p><strong>Answer:</strong> D</p><p>The best solution to reduce data transfer costs for an application frequently accessing S3 buckets in the same region is option D - Deploy an S3 VPC gateway endpoint into the VPC and attach an endpoint policy that allows access to the S3 buckets.</p><p>The key points:</p><ul><li>S3 gateway endpoints allow private connections between VPCs and S3 without going over the public internet.</li><li>This avoids data transfer fees for traffic between the VPC and S3 within the same region.</li><li>An endpoint policy controls access to specific S3 buckets.</li></ul><h2 id="q73" tabindex="-1"><a class="header-anchor" href="#q73"><span>Q73</span></a></h2><p><strong>Answer:</strong> CD</p><p>C because from on-prem network to bastion through internet (using on-prem resource&#39;s public IP), D because bastion and ec2 is in same VPC, meaning bastion can communicate to EC2 via it&#39;s private IP address</p><h2 id="q74" tabindex="-1"><a class="header-anchor" href="#q74"><span>Q74</span></a></h2><p><strong>Answer:</strong> AC</p><p>Web Server Rules: Inbound traffic from 443 (HTTPS) Source 0.0.0.0/0 - Allows inbound HTTPS access from any IPv4 address Database Rules : 1433 (MS SQL)The default port to access a Microsoft SQL Server database, for example, on an Amazon RDS instance</p><p>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/security-group-rules-reference.html</p><h2 id="q75" tabindex="-1"><a class="header-anchor" href="#q75"><span>Q75</span></a></h2><p><strong>Answer:</strong> A</p><p>The catch phrase is &quot;scale up when communication failures are detected&quot; Scaling should not be based on communication failures, that&#39;ll be crying over spilled milk ! or rather too late. So D is wrong.</p><hr><p>Ans A - keep it simple: API Gateway + Lambda + SQS D won&#39;t work: it relies upon a failure detected - by then its too late)</p><h2 id="q76" tabindex="-1"><a class="header-anchor" href="#q76"><span>Q76</span></a></h2><p><strong>Answer:</strong> B</p><p>DMS is for databases and here refers to “JSON files”. Public internet is not reliable. So best option is B.</p><h2 id="q77" tabindex="-1"><a class="header-anchor" href="#q77"><span>Q77</span></a></h2><p><strong>Answer:</strong> C</p><p>(A) - You don&#39;t need to deploy an EC2 instance to host an API - Operational overhead (B) - Same as A (<strong>C</strong>) - Is the answer (D) - AWS Glue gets data from S3, not from API GW. AWS Glue could do ETL by itself, so don&#39;t need lambda. Non sense. https://aws.amazon.com/glue/</p><p>===&gt; I don&#39;&#39;t understand is why we should use Lambda in between to transform data. To me, Kinesis data firehose is enough as it is an extract, transform, and load (ETL) service.</p><p>===&gt; It is because they assume that Kinesis Data Firehose built-in transformations are not enough. So you have to use specific lambda transformation. Please refer to this link : https://aws.amazon.com/kinesis/data-firehose/#:~:text=Amazon%20Kinesis%20Data%20Firehose%20is,data%20stores%2C%20and%20analytics%20services.</p><h2 id="q78" tabindex="-1"><a class="header-anchor" href="#q78"><span>Q78</span></a></h2><p><strong>Answer:</strong> B</p><p>Agreed with option B is the right one. AWS backup retention goes from 1 day to 100 years (or even indefinitely, if you do not enter a retention period), so will meet the requirements.</p><h2 id="q79" tabindex="-1"><a class="header-anchor" href="#q79"><span>Q79</span></a></h2><p><strong>Answer:</strong> A</p><p>On-demand mode is a good option if any of the following are true:</p><ul><li>You create new tables with unknown workloads.</li><li>You have unpredictable application traffic.</li><li>You prefer the ease of paying for only what you use.</li></ul><h2 id="q80" tabindex="-1"><a class="header-anchor" href="#q80"><span>Q80</span></a></h2><p><strong>Answer:</strong> B</p><p>Share the existing KMS key with the MSP external account because it has already been used to encrypt the AMI snapshot.</p><p>https://docs.aws.amazon.com/kms/latest/developerguide/key-policy-modifying-external-accounts.html</p>',39)])])}const c=a(o,[["render",i]]),l=JSON.parse('{"path":"/AWS/SAA/02Examtopics/Questions/0071-Answers.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/SAA/02Examtopics/Questions/0071-Answers.md"}');export{c as comp,l as data};
