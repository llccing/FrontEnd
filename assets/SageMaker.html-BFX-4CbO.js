import{_ as a,c as n,a as t,o as r}from"./app-Dbw06csz.js";const i={};function o(s,e){return r(),n("div",null,[...e[0]||(e[0]=[t('<h2 id="sagemaker" tabindex="-1"><a class="header-anchor" href="#sagemaker"><span>SageMaker</span></a></h2><p>Bringing together widely adopted AWS machine learning (ML) and analytics capabilities, the next generation of Amazon SageMaker delivers an integrated experience for analytics and AI with unified access to all your data. Collaborate and build faster from a unified studio using familiar AWS tools for model development in SageMaker AI (including HyperPod, JumpStart, and MLOps), generative AI, data processing, and SQL analytics, accelerated by Amazon Q Developer, the most capable generative AI assistant for software development. Access all your data whether it’s stored in data lakes, data warehouses, or third-party or federated data sources, with governance built in to meet enterprise security needs.</p><h3 id="amazon-sagemaker-feature-store" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-feature-store"><span>Amazon SageMaker Feature Store</span></a></h3><p>A fully managed service for machine learning features</p><p>Amazon SageMaker Feature Store is a fully managed, purpose-built repository to store, share, and manage features for machine learning (ML) models. Features are inputs to ML models used during training and inference. For example, in an application that recommends a music playlist, features could include song ratings, listening duration, and listener demographics. Features are used repeatedly by multiple teams and feature quality is critical to ensure a highly accurate model. Also, when features used to train models offline in batch are made available for real-time inference, it’s hard to keep the two feature stores synchronized. SageMaker Feature Store provides a secured and unified store to process, standardize, and use features at scale across the ML lifecycle.</p><h3 id="amazon-sagemaker-data-wrangler" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-data-wrangler"><span>Amazon SageMaker Data Wrangler</span></a></h3><p>The fastest and easiest way to prepare data for machine learning - now in SageMaker Canvas.</p><p>Amazon SageMaker Data Wrangler reduces data prep time for tabular, image, and text data from weeks to minutes. With SageMaker Data Wrangler you can simplify data preparation and feature engineering through a visual and natural language interface. Quickly select, import, and transform data with SQL and over 300 built-in transformations without writing code. Generate intuitive data quality reports to detect anomalies across data types, and estimate model performance. Scale to process petabytes of data.</p><h4 id="the-difference-between-sagemaker-feature-store-and-sagemaker-data-wrangler" tabindex="-1"><a class="header-anchor" href="#the-difference-between-sagemaker-feature-store-and-sagemaker-data-wrangler"><span>the difference between SageMaker Feature Store and SageMaker Data Wrangler.</span></a></h4><p>SageMaker Data Wrangler and SageMaker Feature Store solve different parts of the ML data lifecycle:</p><p>SageMaker Data Wrangler (prepare/transform data) Purpose: A data preparation tool to clean, transform, and engineer features from raw data.</p><p>When you use it: During data exploration and feature engineering (before training). What it does: Connects to data sources (S3, Redshift, Athena, Snowflake, etc.) Lets you apply transforms (joins, filters, missing value handling, encoding, scaling, text/date parsing, outlier handling) Can generate a repeatable pipeline (SageMaker Processing job / SageMaker Pipelines) Supports data quality insights and some bias/leakage checks depending on workflow Output: Writes transformed datasets back to S3, and/or exports the steps as code/pipelines. Key idea: It’s an interactive + automatable ETL/feature engineering environment.</p><p>SageMaker Feature Store (store/serve features) Purpose: A centralized repository for engineered features so they can be reused consistently across training and inference.</p><p>When you use it: After you’ve defined features—so you can store them and retrieve them reliably for: model training datasets real-time or batch inference What it does: Manages feature groups (schemas, record identifiers, event times) Supports an offline store (historical features, typically in S3) for training Supports an online store (low-latency lookup) for real-time inference Helps prevent training/serving skew by using the same feature definitions/data source Enables feature reuse across teams and models, with metadata and lineage Output: Feature values accessible via APIs for training/inference.</p><p>Core difference in one line Data Wrangler = create/transform features (feature engineering + ETL). Feature Store = persist, manage, and serve features (reuse + consistency for training/inference).</p><p>How they work together (common pattern) Use Data Wrangler to clean raw data and engineer features. Write the resulting features into Feature Store (offline and/or online). Training pulls historical features from the offline store. Real-time inference queries the online store for the latest features.</p><p>Quick “which should I use?” guide Need to explore data and build transformations quickly? → Data Wrangler Need a central place to reuse features and serve them in production (online/offline)? → Feature Store Doing production ML with multiple models/teams and want consistency? → Feature Store (often plus Data Wrangler upstream)</p><p>If you tell me whether your use case is batch scoring, real-time inference, or training-only, I can suggest a typical architecture and which components are worth adopting.</p><h3 id="amazon-sagemaker-clarify" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-clarify"><span>Amazon SageMaker Clarify</span></a></h3><p>Evaluate models and explain model predictions.</p><h3 id="amazon-sagemaker-model-cards" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-model-cards"><span>Amazon SageMaker Model Cards</span></a></h3><p>Use Amazon SageMaker Model Cards to document critical details about your machine learning (ML) models in a single place for streamlined governance and reporting. Model cards can help you to capture key information about your models throughout their lifecycle and implement responsible AI practices.</p><p>Catalog details such as the intended use and risk rating of a model, training details and metrics, evaluation results and observations, and additional call-outs such as considerations, recommendations, and custom information. By creating model cards, you can do the following:</p><p>Provide guidance on how a model should be used.</p><p>Support audit activities with detailed descriptions of model training and performance.</p><p>Communicate how a model is intended to support business goals.</p><p>Model cards provide prescriptive guidance on what information to document and include fields for custom information. After creating a model card, you can export it to a PDF or download it to share with relevant stakeholders. Any edits other than an approval status update made to a model card result in additional model card versions in order to have an immutable record of model changes.</p><h3 id="amazon-sagemaker-model-monitor" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-model-monitor"><span>Amazon SageMaker Model Monitor</span></a></h3><p>Keep machine learning models accurate over time</p><p>Amazon SageMaker Model Monitor helps you maintain high quality machine learning (ML) models by automatically detecting and alerting on inaccurate predictions from models deployed in production.</p><p>The accuracy of ML models can deteriorate over time, a phenomenon known as model drift. Many factors can cause model drift such as changes in model features. The accuracy of ML models can also be affected by concept drift, the difference between data used to train models and data used during inference.</p><p>Amazon SageMaker Model Monitor helps you maintain high quality ML models by detecting model and concept drift in real-time, and sending you alerts so you can take immediate action. Model and concept drift are detected by monitoring the quality of the model based on independent and dependent variables. Independent variables (also known as features) are the inputs to an ML model, and dependent variables are the outputs of the model. For example, with an ML model predicting a bank loan approval, independent variables could be age, income, and credit history of the applicant, and the dependent variable would be the actual result of the loan application. Further, SageMaker Model Monitor constantly monitors model performance characteristics such as accuracy which measures the number of correct predictions compared to the total number of predictions so you can take action to address anomalies.</p><p>Additionally, SageMaker Model Monitor is integrated with Amazon SageMaker Clarify to help you identify potential bias in your ML models with model bias detection.</p><h3 id="amazon-sagemaker-serverless-inference" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-serverless-inference"><span>Amazon SageMaker Serverless Inference</span></a></h3><p>Amazon SageMaker Serverless Inference is a purpose-built inference option that makes it easy for you to deploy and scale machine learning (ML) models. It provides a pay-per-use model, which is ideal for services where endpoint invocations are infrequent and unpredictable. Unlike a real-time hosting endpoint, which is backed by a long-running instance, compute resources for serverless endpoints are provisioned on demand, thereby eliminating the need to choose instance types or manage scaling policies.</p><h3 id="amazon-sagemaker-jumpstart" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-jumpstart"><span>Amazon SageMaker JumpStart</span></a></h3><p>Machine learning (ML) hub with foundation models, built-in algorithms, and prebuilt ML solutions that you can deploy with just a few clicks</p><p>Amazon SageMaker JumpStart is a machine learning (ML) hub that can help you accelerate your ML journey. With SageMaker JumpStart, you can evaluate, compare, and select FMs quickly based on predefined quality and responsibility metrics to perform tasks like article summarization and image generation. Pretrained models are fully customizable for your use case with your data, and you can easily deploy them into production with the user interface or SDK. You can also share artifacts, including models and notebooks, within your organization to accelerate model building and deployment, and admins can control which models are visible to users within their organization.</p><h3 id="amazon-sagemaker-endpoints" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-endpoints"><span>Amazon SageMaker Endpoints</span></a></h3><p>Amazon SageMaker Endpoints are secure HTTPS URLs for deploying trained ML models, making them accessible for real-time predictions (inference) at scale, managed by AWS for auto-scaling, instance management (CPU/GPU), and hosting your model artifacts within containers on EC2 instances, allowing seamless integration with applications via standard HTTP requests. They handle the heavy lifting of infrastructure, letting you focus on model serving, with options for custom containers and various instance types for different workloads, like large language models (LLMs).</p><h3 id="amazon-sagemaker-canvas" tabindex="-1"><a class="header-anchor" href="#amazon-sagemaker-canvas"><span>Amazon SageMaker Canvas</span></a></h3><p>Build highly accurate ML models using a visual interface, no code required</p><p>Amazon SageMaker Canvas gives you the ability to use machine learning to generate predictions without needing to write any code. The following are some use cases where you can use SageMaker Canvas:</p><ul><li>Predict customer churn</li><li>Plan inventory efficiently</li><li>Optimize price and revenue</li><li>Improve on-time deliveries</li><li>Classify text or images based on custom categories</li><li>Identify objects and text in images</li><li>Extract information from documents</li></ul><h3 id="sagemaker-experiments" tabindex="-1"><a class="header-anchor" href="#sagemaker-experiments"><span>SageMaker Experiments</span></a></h3><p>Amazon SageMaker Experiments Classic is a capability of Amazon SageMaker AI that lets you create, manage, analyze, and compare your machine learning experiments in Studio Classic. Use SageMaker Experiments to view, manage, analyze, and compare both custom experiments that you programmatically create and experiments automatically created from SageMaker AI jobs.</p><p>Experiments Classic automatically tracks the inputs, parameters, configurations, and results of your iterations as runs. You can assign, group, and organize these runs into experiments. SageMaker Experiments is integrated with Amazon SageMaker Studio Classic, providing a visual interface to browse your active and past experiments, compare runs on key performance metrics, and identify the best performing models. SageMaker Experiments tracks all of the steps and artifacts that went into creating a model, and you can quickly revisit the origins of a model when you are troubleshooting issues in production, or auditing your models for compliance verifications.</p>',47)])])}const l=a(i,[["render",o]]),c=JSON.parse('{"path":"/AWS/CPE/01Features/SageMaker.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212680000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"8dc20e2f1b4b500b4a8b691792c2c9b3c12addca","time":1768212680000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Merge pull request #66 from llccing/copilot/fix-vite-build-error"}]},"filePathRelative":"AWS/CPE/01Features/SageMaker.md"}');export{l as comp,c as data};
