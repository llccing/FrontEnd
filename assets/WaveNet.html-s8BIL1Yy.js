import{_ as t,c as n,b as e,o as s}from"./app-DxUSmTbc.js";const i={};function o(r,a){return s(),n("div",null,[...a[0]||(a[0]=[e("h2",{id:"wavenet",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#wavenet"},[e("span",null,"WaveNet")])],-1),e("p",null,"WaveNet is a deep neural network for generating raw audio. It was created by researchers at London-based AI firm DeepMind. The technique, outlined in a paper in September 2016, is able to generate relatively realistic-sounding human-like voices by directly modelling waveforms using a neural network method trained with recordings of real speech. Tests with US English and Mandarin reportedly showed that the system outperforms Google's best existing text-to-speech (TTS) systems, although as of 2016 its text-to-speech synthesis still was less convincing than actual human speech. WaveNet's ability to generate raw waveforms means that it can model any kind of audio, including music.",-1)])])}const c=t(i,[["render",o]]),m=JSON.parse('{"path":"/AWS/CPE/02Terms/WaveNet.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/CPE/02Terms/WaveNet.md"}');export{c as comp,m as data};
