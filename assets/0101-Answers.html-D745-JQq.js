import{_ as t,c as a,a as n,o}from"./app-Dbw06csz.js";const s={};function i(r,e){return o(),a("div",null,[...e[0]||(e[0]=[n('<h2 id="q101" tabindex="-1"><a class="header-anchor" href="#q101"><span>Q101</span></a></h2><p><strong>Answer:</strong> A</p><p>The correct answer is option A.</p><p>To enable Internet access for the private subnets, the solutions architect should create three NAT gateways, one for each public subnet in each Availability Zone (AZ). NAT gateways allow private instances to initiate outbound traffic to the Internet but do not allow inbound traffic from the Internet to reach the private instances.</p><p>The solutions architect should then create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ. This will allow instances in the private subnets to access the Internet through the NAT gateways in the public subnets.</p><h2 id="q102" tabindex="-1"><a class="header-anchor" href="#q102"><span>Q102</span></a></h2><p><strong>Answer:</strong> B and E</p><p>E is correct https://aws.amazon.com/blogs/storage/migrating-storage-with-aws-datasync/</p><h2 id="q103" tabindex="-1"><a class="header-anchor" href="#q103"><span>Q103</span></a></h2><p><strong>Answer:</strong> A</p><p>This is the purpose of bookmarks: &quot;AWS Glue tracks data that has already been processed during a previous run of an ETL job by persisting state information from the job run. This persisted state information is called a job bookmark. Job bookmarks help AWS Glue maintain state information and prevent the reprocessing of old data.&quot; https://docs.aws.amazon.com/glue/latest/dg/monitor-continuations.html</p><h2 id="q104" tabindex="-1"><a class="header-anchor" href="#q104"><span>Q104</span></a></h2><p><strong>Answer:</strong> AC</p><p>I think it is AC, reason is they require a solution that is highly available. AWS Shield can handle the DDoS attacks. To make the solution HA you can use cloud front. AC seems to be the best answer imo.</p><h2 id="q105" tabindex="-1"><a class="header-anchor" href="#q105"><span>Q105</span></a></h2><p><strong>Answer:</strong> D</p><p>Best way to check it... The question is taken from the example shown here in the documentation: https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-use-resource-based.html#eb-lambda-permissions</p><h2 id="q106" tabindex="-1"><a class="header-anchor" href="#q106"><span>Q106</span></a></h2><p><strong>Answer:</strong> D</p><p>SSE-KMS provides a secure and efficient way to encrypt data at rest in S3. SSE-KMS uses KMS to manage the encryption keys securely. With SSE-KMS, encryption keys can be automatically rotated using KMS key rotation feature, which simplifies the key management process and ensures compliance with the requirement to rotate keys every year.</p><p>Additionally, SSE-KMS provides built-in audit logging for encryption key usage through CloudTrail, which captures API calls related to the management and usage of KMS keys. This meets the requirement for logging key usage for auditing purposes.</p><p>Option A (SSE-C) requires customers to provide their own encryption keys, but it does not provide key rotation or built-in logging of key usage. Option B (SSE-S3) uses Amazon S3 managed keys for encryption, which simplifies key management but does not provide key rotation or detailed key usage logging. Option C (SSE-KMS with manual rotation) uses AWS KMS keys but requires manual rotation, which is less operationally efficient than the automatic key rotation available with option D.</p><h2 id="q107" tabindex="-1"><a class="header-anchor" href="#q107"><span>Q107</span></a></h2><p><strong>Answer:</strong> D</p><p>I dont understand why you will vote B? how are you going to store data with just lambda?</p><blockquote><p>Which action meets these requirements for storing and retrieving location data</p></blockquote><p>In this use case there will obviously be a ton of data and you want to get real-time location data of the bicycles, and to analyze all these info kinesis is the one that makes most sense here.</p><h2 id="q108" tabindex="-1"><a class="header-anchor" href="#q108"><span>Q108</span></a></h2><p><strong>Answer:</strong> D</p><p>The correct answer is <strong>D</strong>: Subscribe to an RDS event notification and send an Amazon Simple Notification Service (Amazon SNS) topic fanned out to multiple Amazon Simple Queue Service (Amazon SQS) queues. Use AWS Lambda functions to update the targets.</p><h3 id="reasoning" tabindex="-1"><a class="header-anchor" href="#reasoning"><span>Reasoning:</span></a></h3><ul><li><p><strong>RDS Event Notifications</strong>: While RDS event notifications can alert you to changes in the database instance status, they do not directly notify you of specific data changes within tables. Thus, using RDS event notifications alone is not sufficient for capturing when a specific record, such as an automobile listing, is updated or deleted.</p></li><li><p><strong>SNS and SQS</strong>: By using SNS to fan out messages to multiple SQS queues, you can effectively distribute the information to multiple targets. Each target can have its own SQS queue, allowing for independent processing. This setup is scalable and decouples the message distribution from the processing logic.</p></li><li><p><strong>AWS Lambda Functions</strong>: These can be triggered by messages in the SQS queues to perform specific actions required by each target system, such as updating or removing listings.</p></li></ul><h3 id="why-not-a-or-b" tabindex="-1"><a class="header-anchor" href="#why-not-a-or-b"><span>Why Not A or B:</span></a></h3><ul><li><strong>Direct Lambda Trigger on RDS</strong>: AWS Lambda cannot be directly triggered by changes in RDS databases without additional services like DMS or Aurora with Kinesis. Therefore, options A and B, which suggest directly triggering Lambda on database updates, are not feasible.</li></ul><h3 id="why-not-c" tabindex="-1"><a class="header-anchor" href="#why-not-c"><span>Why Not C:</span></a></h3><ul><li><strong>RDS Event Notification to SQS/SNS</strong>: While this option uses RDS event notifications, it suggests sending them to an SQS queue first, which is not as efficient for fanning out to multiple systems compared to using SNS directly for fanning out.</li></ul><p>Thus, option D provides a more scalable and decoupled solution using SNS for fanning out messages to multiple SQS queues and Lambda functions for processing.</p><hr><p>key point: Even though lambda is integrated with RDS, it is not best practices for multiple consumers. SNS + SQS Fan-Out should be chosen https://aws.amazon.com/getting-started/hands-on/send-fanout-event-notifications/?nc1=h_ls</p><h2 id="q109" tabindex="-1"><a class="header-anchor" href="#q109"><span>Q109</span></a></h2><p><strong>Answer:</strong> D</p><p>A - No as &quot;specific users can delete&quot; B - No as &quot;nonspecific amount of time&quot; C - No as &quot;prevent the data from being change&quot; D - The answer: &quot;The Object Lock legal hold operation enables you to place a legal hold on an object version. Like setting a retention period, a legal hold prevents an object version from being overwritten or deleted. However, a legal hold doesn&#39;t have an associated retention period and remains in effect until removed.&quot; https://docs.aws.amazon.com/AmazonS3/latest/userguide/batch-ops-legal-hold.html</p><h2 id="q110" tabindex="-1"><a class="header-anchor" href="#q110"><span>Q110</span></a></h2><p><strong>Answer:</strong> C and D</p><p>CD is the more appropriate solution bec. when the user uploads the images, it will directly uploaded to the S3 while if BD, when the user uploads the images, it will first go to the web server then to the S3 bucket and This can cause a slow upload process since the web server is processing the download from the user, then upload to the s3 bucket.</p>',45)])])}const c=t(s,[["render",i]]),l=JSON.parse('{"path":"/AWS/SAA/02Examtopics/Questions/0101-Answers.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212680000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"8dc20e2f1b4b500b4a8b691792c2c9b3c12addca","time":1768212680000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Merge pull request #66 from llccing/copilot/fix-vite-build-error"}]},"filePathRelative":"AWS/SAA/02Examtopics/Questions/0101-Answers.md"}');export{c as comp,l as data};
