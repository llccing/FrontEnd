import{_ as i,c as a,b as e,o as n}from"./app-DxUSmTbc.js";const o={};function r(s,t){return n(),a("div",null,[...t[0]||(t[0]=[e("p",null,"44.A company is developing a new model to predict the prices of specific items. The model performed well on the training dataset. When the company deployed the model to production, the model's performance decreased significantly. What should the company do to mitigate this problem? A.Reduce the volume of data that is used in training. B.Add hyperparameters to the model. C.Increase the volume of data that is used in training. D.Increase the model training time",-1),e("p",null,"The correct answer is C. Increase the volume of data that is used in training.",-1),e("p",null,"Explanation",-1),e("p",null,"The Diagnosis: Overfitting The scenario described—where a model performs very well on training data but poorly on production (unseen) data—is the textbook definition of overfitting. This means the model has memorized the specific noise and details of the training set rather than learning the general underlying patterns. Consequently, it cannot generalize to new data.",-1),e("p",null,"Why Option C is the solution: More Data leads to better Generalization: By increasing the volume of training data, you expose the model to more variations and examples. This forces the model to focus on the true relationships (the signal) rather than the random fluctuations (the noise) present in a small dataset.",-1),e("p",null,"Why the other options are incorrect:",-1),e("p",null,`A. Reduce the volume of data: This would make the problem worse. With less data, it is easier for the model to memorize specific examples, leading to higher variance and more overfitting. B. Add hyperparameters: This is not a standard solution. While tuning hyperparameters (specifically regularization parameters) can help, simply "adding" them doesn't fix the issue. Furthermore, making a model more complex often increases overfitting. D. Increase the model training time: This would likely make the problem worse. Training a model for too long allows it to continue optimizing specifically for the training set, deepening the overfitting. (In fact, reducing training time via "early stopping" is a common technique to fix this issue).`,-1)])])}const m=i(o,[["render",r]]),d=JSON.parse('{"path":"/AWS/CPE/03Trick-Questions.md/044-performance-decreased.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/CPE/03Trick-Questions.md/044-performance-decreased.md"}');export{m as comp,d as data};
