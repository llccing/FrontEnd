import{_ as a,c as t,a as n,o as i}from"./app-DxUSmTbc.js";const s={};function o(r,e){return i(),t("div",null,[...e[0]||(e[0]=[n('<h2 id="q91" tabindex="-1"><a class="header-anchor" href="#q91"><span>Q91</span></a></h2><p><strong>Answer:</strong> A</p><p>Gateway endpoints provide reliable connectivity to Amazon S3 and DynamoDB without requiring an internet gateway or a NAT device for your VPC. It should be option A.</p><p>https://docs.aws.amazon.com/vpc/latest/privatelink/gateway-endpoints.html</p><hr><p>B. Creating an S3 in a private subnet restricts direct internet access to the bucket but does not provide a direct and secure connection between the EC2and the S3. The application would still need to traverse the internet to access the S3 API.</p><p>C. Creating an S3 in the same Region as the EC2 does not inherently prevent traffic from traversing the internet.</p><p>D. Configuring a NAT gateway allows outbound internet connectivity for resources in private subnets, but it does not provide a direct and secure connection to the S3 service. The traffic from the EC2 to the S3 API would still traverse the internet.</p><p>The most suitable solution is to configure an S3 gateway endpoint (option A). It provides a secure and private connection between the VPC and the S3 service without requiring the traffic to traverse the internet. With an S3 gateway endpoint, the EC2 can access the S3 API directly within the VPC, meeting the security requirement of preventing traffic from traveling across the internet.</p><h2 id="q92" tabindex="-1"><a class="header-anchor" href="#q92"><span>Q92</span></a></h2><p><strong>Answer:</strong> AC</p><p>A: VPC S3 gateway for direct connection (no public internet) to access S3 C: Bucket policy to secure access and only allow the VPC application tier to access it</p><p>B: Opens up to public D: Not secure to copy credentials E: NAT instance (obsolete now) is not useful for limiting resource access, it&#39;s for subnet connections</p><h2 id="q93" tabindex="-1"><a class="header-anchor" href="#q93"><span>Q93</span></a></h2><p><strong>Answer:</strong> B</p><p>Aura MySQL is very fast in comparison to RDS for creating a clone of DB, you can create a even clone of a clone while you still work on your own clone, this will allow the dev team continue working during cloning step. https://aws.amazon.com/blogs/aws/amazon-aurora-fast-database-cloning/</p><h2 id="q94" tabindex="-1"><a class="header-anchor" href="#q94"><span>Q94</span></a></h2><p><strong>Answer:</strong> C</p><p>A. Configuring EMR and an Aurora DB cluster for this use case would introduce unnecessary complexity and operational overhead. EMR is typically used for processing large datasets and running big data frameworks like Apache Spark or Hadoop.</p><p>B. While using S3 event notifications and SQS for decoupling is a good approach, using EC2 to process the data would introduce operational overhead in terms of managing and scaling the EC2.</p><p>D. Using EventBridge and Kinesis Data Streams for this use case would introduce additional complexity and operational overhead compared to the other options. EventBridge and Kinesis are typically used for real-time streaming and processing of large volumes of data.</p><p>In summary, option C is the recommended solution as it provides a serverless and scalable approach for processing uploaded files using S3 event notifications, SQS, and Lambda. It offers low operational overhead, automatic scaling, and efficient handling of varying demand. Storing the resulting JSON file in DynamoDB aligns with the requirement of saving the data for later analysis.</p><h2 id="q95" tabindex="-1"><a class="header-anchor" href="#q95"><span>Q95</span></a></h2><p><strong>Answer:</strong> D</p><p>A. In a Multi-AZ deployment, a standby replica of the database is created in a different AZ for high availability and automatic failover purposes. However, serving read requests from the primary AZ alone would not effectively separate read and write traffic. Both read and write traffic would still be directed to the primary database instance, which might not fully optimize performance.</p><p>B. The secondary instance in a Multi-AZ deployment is intended for failover and backup purposes, not for actively serving read traffic. It operates in a standby mode and is not optimized for handling read queries efficiently.</p><p>C. Configuring the read replicas with half of the compute and storage resources as the source database might not be optimal. It&#39;s generally recommended to configure the read replicas with the same compute and storage resources as the source database to ensure they can handle the read workload effectively.</p><p>D. Configuring the read replicas with the same compute and storage resources as the source database ensures that they can handle the read workload efficiently and provide the required performance boost.</p><h2 id="q96" tabindex="-1"><a class="header-anchor" href="#q96"><span>Q96</span></a></h2><p><strong>Answer:</strong> C</p><p>Ans C - must be in us-east-1 region and CIDR address is in allowable range (/24)</p><hr><p>The first rule allows users with the specified IP CIDR to terminate instances, and the second rule specifies that the region must be us-east-1 for the termination process to be allowed, hence C is the correct answer.</p><h2 id="q97" tabindex="-1"><a class="header-anchor" href="#q97"><span>Q97</span></a></h2><p><strong>Answer:</strong> D</p><p>A. EFS does not provide native integration with AD for access control. While you can configure EFS to work with AD, it requires additional setup and is not as straightforward as using a dedicated Windows file system like FSx for Windows File Server.</p><p>B. It may introduce additional complexity for this use case. Creating an SMB file share using AWS Storage Gateway would require maintaining the gateway and managing the synchronization between on-premises and AWS storage.</p><p>C. S3 does not natively provide the SMB file protocol required for MS SharePoint and Windows shared file storage. While it is possible to mount an S3 as a volume using 3rd-party tools or configurations, it is not the recommended.</p><p>D. FSx for Windows File Server is a fully managed, highly available file storage service that is compatible with MSWindows shared file storage requirements. It provides native integration with AD, allowing for seamless access control and authentication using existing AD user accounts.</p><h2 id="q98" tabindex="-1"><a class="header-anchor" href="#q98"><span>Q98</span></a></h2><p><strong>Answer:</strong> C</p><p>https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-visibility-timeout.html</p><p>this is important part: Immediately after a message is received, it remains in the queue. To prevent other consumers from processing the message again, Amazon SQS sets a visibility timeout, a period of time during which Amazon SQS prevents other consumers from receiving and processing the message. The default visibility timeout for a message is 30 seconds. The minimum is 0 seconds. The maximum is 12 hours.</p><h2 id="q99" tabindex="-1"><a class="header-anchor" href="#q99"><span>Q99</span></a></h2><p><strong>Answer:</strong> D</p><p>Answer is D. Lustre in the question is only available as FSx https://aws.amazon.com/fsx/lustre/</p><h2 id="q100" tabindex="-1"><a class="header-anchor" href="#q100"><span>Q100</span></a></h2><p><strong>Answer:</strong> D</p><p>Correct Answer is C: EBS is not highly available.</p><hr><p>EBS volumes are not Multi-AZ. EBS io2 types are multi-attach within the same AZ. EFS is multi-AZ</p>',51)])])}const d=a(s,[["render",o]]),p=JSON.parse('{"path":"/AWS/SAA/02Examtopics/Questions/0091-Answers.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/SAA/02Examtopics/Questions/0091-Answers.md"}');export{d as comp,p as data};
