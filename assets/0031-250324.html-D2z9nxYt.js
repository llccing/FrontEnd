import{_ as e,c as n,a as t,o as s}from"./app-Dbw06csz.js";const i={};function r(o,a){return s(),n("div",null,[...a[0]||(a[0]=[t('<h1 id="result" tabindex="-1"><a class="header-anchor" href="#result"><span>Result</span></a></h1><ul><li>69% Failed</li><li>1h18mins</li></ul><h2 id="_1-20" tabindex="-1"><a class="header-anchor" href="#_1-20"><span>1/20</span></a></h2><p>For a big oracle database which running for 15 years. you can also consider to use Database Migration Service(DMS) to migrate the database servers to Amazon RDS.</p><h2 id="_2-20" tabindex="-1"><a class="header-anchor" href="#_2-20"><span>2/20</span></a></h2><p>For large file such as terabytes of data, you can use AWS DataSync, which can handle occasional interruptions in internet connectivity.</p><h2 id="_3-20" tabindex="-1"><a class="header-anchor" href="#_3-20"><span>3/20</span></a></h2><p>A second Elastic Network Interface, attach it to the EC2 instance configured with the private IP address. Move the network interface to standby instance if the primary EC2 instance becomes unreachable.</p><h2 id="_4-20" tabindex="-1"><a class="header-anchor" href="#_4-20"><span>4/20</span></a></h2><p>For the first 30 days, the file should be visist mroe frequent. after 30 days, can move to S3 Glacier.</p><h2 id="_5-20" tabindex="-1"><a class="header-anchor" href="#_5-20"><span>5/20</span></a></h2><p>EC2 Auto Scaling group and ALB spanning multiple AZs.</p><h2 id="_6-20" tabindex="-1"><a class="header-anchor" href="#_6-20"><span>6/20</span></a></h2><p>case: ALB =&gt; EC2, Aurora database. requirement: more resilient to periodic increases in request rates. solutions:</p><ul><li>AWS Global Accelerator</li><li>CloudFront in front of the ALB</li></ul><h2 id="_7-20" tabindex="-1"><a class="header-anchor" href="#_7-20"><span>7/20</span></a></h2><p>ALB listener can handle URL query string; and Route 53 does not support URL query string based routing.</p><h2 id="_8-20" tabindex="-1"><a class="header-anchor" href="#_8-20"><span>8/20</span></a></h2><ul><li>backup and restore, RPO in hours, RTO in 24 hours or less.</li><li>Pilot light, RPO in minutes, RTO in hours.</li><li>Warm standby, RPO in seconds, RTO in minutes.</li><li>Multi-region (multi-site) active-active, RPO near zero, RTO potentially zero.</li></ul><h2 id="_9-20" tabindex="-1"><a class="header-anchor" href="#_9-20"><span>9/20</span></a></h2><p>if the number of messages increase to 100,000 each second. only SNS can support. coz Kinese Data Stream can 1,000 records per second for writes.</p><p>So we should use a SNS topic, and multiple SQS subscriptions, and configured the consumer applications to process the messages from the queues.</p><h2 id="_10-20" tabindex="-1"><a class="header-anchor" href="#_10-20"><span>10/20</span></a></h2><p>vpc peering connection and PrivateLink connection can use for two aws account, which the service is in private subnet.</p><h2 id="_11-20" tabindex="-1"><a class="header-anchor" href="#_11-20"><span>11/20</span></a></h2><p>if you use spot instance, and want to stoped but not terminated, in case the spot instance are interrupted.</p><h2 id="_12-20" tabindex="-1"><a class="header-anchor" href="#_12-20"><span>12/20</span></a></h2><p>use S3 replication between the S3 butckets. Create an S3 event notification for the analysis S3 bucket. Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure S3:ObjectCreated:Put as the event type.</p><h2 id="_13-20" tabindex="-1"><a class="header-anchor" href="#_13-20"><span>13/20</span></a></h2><p>Aurora Global Database, span multiple Regions, enabling low latency global reads. From the name &quot;Global&quot;, you should know that will enable multiple Regions.</p><h2 id="_14-20" tabindex="-1"><a class="header-anchor" href="#_14-20"><span>14/20</span></a></h2><p>use NLB as the Global Accelerator endpoint in each Region. CloudFront cannot point to latency record as an origin.</p><h2 id="_15-20" tabindex="-1"><a class="header-anchor" href="#_15-20"><span>15/20</span></a></h2><p>EFS Throughput Modes provides throughput with the ability to be shared across instances. And the EBS volume cannot be shared across instances except multi-attach.</p><h2 id="_16-20" tabindex="-1"><a class="header-anchor" href="#_16-20"><span>16/20</span></a></h2><p>first is key-value, so should use DynamoDB. then, miscroseconds latency, should be DynamoDB Accelerator. coz Aurora + ElasticCache cannot meet the miscroseconds latency.</p><h2 id="_17-20" tabindex="-1"><a class="header-anchor" href="#_17-20"><span>17/20</span></a></h2><p>use Customer managed keys. SSE-KMS. SSE-S3 would not allow key management and audit for the key usage.</p><h2 id="_18-20" tabindex="-1"><a class="header-anchor" href="#_18-20"><span>18/20</span></a></h2><p>ALB + Global Accelerator.</p><h2 id="_19-20" tabindex="-1"><a class="header-anchor" href="#_19-20"><span>19/20</span></a></h2><p>Aurora Serverless for MySQL, ideal for infrequent access patterns with minimal downtime and allows you to provision a MySQL instance without selecting a particular instance type.</p><h2 id="_20-20" tabindex="-1"><a class="header-anchor" href="#_20-20"><span>20/20</span></a></h2><p>point is create CloudFront origin group with two buckets, 1th is primary, 2th is secondary. then can implement failover handling for the primary and standby bucket.</p>',44)])])}const h=e(i,[["render",r]]),l=JSON.parse('{"path":"/AWS/SAA/03PreExams/0031-250324.html","title":"Result","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212680000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"8dc20e2f1b4b500b4a8b691792c2c9b3c12addca","time":1768212680000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Merge pull request #66 from llccing/copilot/fix-vite-build-error"}]},"filePathRelative":"AWS/SAA/03PreExams/0031-250324.md"}');export{h as comp,l as data};
