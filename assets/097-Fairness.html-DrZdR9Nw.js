import{_ as i,c as a,a as t,o as n}from"./app-Dbw06csz.js";const o={};function s(r,e){return n(),a("div",null,[...e[0]||(e[0]=[t("<p>A company is developing a mobile ML app that uses a phone&#39;s camera to diagnose and treat insect bites. The company wants to train an image classification model by using a diverse dataset of insect bite photos from different genders, ethnicities, and geographic locations around the world. Which principle of responsible Al does the company demonstrate in this scenario? A.Fairness B.Explainability C.Governance D.Transparency</p><p>The correct answer is A. Fairness.</p><p>By intentionally sourcing a diverse dataset that includes different genders, ethnicities, and geographic locations, the company is practicing Fairness. This principle ensures that the AI model performs equitably for all users and does not develop biases against specific groups of people.</p><p>Why Fairness is the Key Principle In medical or diagnostic AI, skin tone and environmental factors can significantly change how a condition (like an insect bite) appears.</p><ul><li>Bias Mitigation: If the model were trained only on light-skinned individuals from one region, it might fail to accurately diagnose bites on darker skin tones or recognize species found in different parts of the world.</li><li>Inclusivity: Ensuring the dataset represents the global population minimizes &quot;algorithmic bias,&quot; where the model&#39;s accuracy varies significantly between demographic groups.</li></ul><p>Why the other options are incorrect:</p><p>Principle,Definition,Why it doesn&#39;t fit this specific action</p><p>B. Explainability,The ability to understand how a model arrived at a specific decision or output.,&quot;While important for a medical app, diversifying the training data doesn&#39;t inherently explain the model&#39;s logic.&quot; C. Governance,&quot;The framework of rules, roles, and processes used to manage an organization&#39;s AI.&quot;,&quot;Governance is the &quot;&quot;policy&quot;&quot; level (who is responsible for what), whereas diversity in data is a technical &quot;&quot;fairness&quot;&quot; implementation.&quot; D. Transparency,&quot;Being open about how the AI was built, what data was used, and its limitations.&quot;,Transparency would be telling the public about the dataset; the act of making the dataset diverse is an act of Fairness.</p><p>The &quot;Four Pillars&quot; of Responsible AI</p><p>Fairness: Avoiding bias and ensuring equitable outcomes.</p><p>Privacy &amp; Security: Protecting user data (especially sensitive medical photos).</p><p>Reliability &amp; Safety: Ensuring the app doesn&#39;t give dangerous medical advice.</p><p>Transparency &amp; Accountability: Being clear about how the app works and who is responsible for its errors.</p><p>Important Note: AI-driven medical tools should generally be used as a reference rather than a definitive diagnosis. It is always recommended to consult a healthcare professional for treatment.</p>",14)])])}const l=i(o,[["render",s]]),p=JSON.parse('{"path":"/AWS/CPE/03Trick-Questions.md/097-Fairness.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212680000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"8dc20e2f1b4b500b4a8b691792c2c9b3c12addca","time":1768212680000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Merge pull request #66 from llccing/copilot/fix-vite-build-error"}]},"filePathRelative":"AWS/CPE/03Trick-Questions.md/097-Fairness.md"}');export{l as comp,p as data};
