import{_ as r,c as n,b as e,o as t}from"./app-DxUSmTbc.js";const s={};function i(o,a){return t(),n("div",null,[...a[0]||(a[0]=[e("h2",{id:"generative-pre-trained-transformers-gpt",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#generative-pre-trained-transformers-gpt"},[e("span",null,"Generative pre-trained transformers （GPT）")])],-1),e("p",null,"Generative Pre-trained Transformers, commonly known as GPT, are a family of neural network models that uses the transformer architecture and is a key advancement in artificial intelligence (AI) powering generative AI applications such as ChatGPT. GPT models give applications the ability to create human-like text and content (images, music, and more), and answer questions in a conversational manner. Organizations across industries are using GPT models and generative AI for Q&A bots, text summarization, content generation, and search.",-1)])])}const c=r(s,[["render",i]]),l=JSON.parse('{"path":"/AWS/CPE/02Terms/Generate-pre-trained-Transformers.html","title":"","lang":"zh-CN","frontmatter":{},"git":{"updatedTime":1768212945000,"contributors":[{"name":"Rowan Liu","username":"","email":"lcf33123@gmail.com","commits":1}],"changelog":[{"hash":"510851a2e40013ba249eb2696f9e38f188ca533a","time":1768212945000,"email":"lcf33123@gmail.com","author":"Rowan Liu","message":"Update README.md"}]},"filePathRelative":"AWS/CPE/02Terms/Generate-pre-trained-Transformers.md"}');export{c as comp,l as data};
