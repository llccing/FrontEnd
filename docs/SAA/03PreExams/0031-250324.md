# Result
- 69% Failed
- 1h18mins

## 1/20
For a big oracle database which running for 15 years. you can also consider to use Database Migration Service(DMS) to migrate the database servers to Amazon RDS.

## 2/20
For large file such as terabytes of data, you can use AWS DataSync, which can handle occasional interruptions in internet connectivity.

## 3/20
A second Elastic Network Interface, attach it to the EC2 instance configured with the private IP address. Move the network interface to standby instance if the primary EC2 instance becomes unreachable.

## 4/20
For the first 30 days, the file should be visist mroe frequent. after 30 days, can move to S3 Glacier.

## 5/20
EC2 Auto Scaling group and ALB spanning multiple AZs.

## 6/20
case: ALB => EC2, Aurora database.
requirement: more resilient to periodic increases in request rates.
solutions:
- AWS Global Accelerator
- CloudFront in front of the ALB

## 7/20
ALB listener can handle URL query string; and Route 53 does not support URL query string based routing.

## 8/20
- backup and restore, RPO in hours, RTO in 24 hours or less.
- Pilot light, RPO in minutes, RTO in hours.
- Warm standby, RPO in seconds, RTO in minutes.
- Multi-region (multi-site) active-active, RPO near zero, RTO potentially zero.

## 9/20
if the number of messages increase to 100,000 each second. only SNS can support. 
coz Kinese Data Stream can 1,000 records per second for writes.

So we should use a SNS topic, and multiple SQS subscriptions, 
and configured the consumer applications to process the messages from the queues.

## 10/20
vpc peering connection and PrivateLink connection can use for two aws account, which the service is in private subnet.

## 11/20
if you use spot instance, and want to stoped but not terminated, in case the spot instance are interrupted.

## 12/20
use S3 replication between the S3 butckets. Create an S3 event notification for the analysis S3 bucket. 
Configure Lambda and SageMaker Pipelines as destinations of the event notification. Configure S3:ObjectCreated:Put 
as the event type.

## 13/20
Aurora Global Database, span multiple Regions, enabling low latency global reads. From the name "Global", 
you should know that will enable multiple Regions.

## 14/20
use NLB as the Global Accelerator endpoint in each Region.
CloudFront cannot point to latency record as an origin.

## 15/20
EFS Throughput Modes provides throughput with the ability to be shared across instances.
And the EBS volume cannot be shared across instances except multi-attach.

## 16/20
first is key-value, so should use DynamoDB.
then, miscroseconds latency, should be DynamoDB Accelerator.
coz Aurora + ElasticCache cannot meet the miscroseconds latency.

## 17/20
use Customer managed keys. SSE-KMS.
SSE-S3 would not allow key management and audit for the key usage.

## 18/20
ALB + Global Accelerator. 

## 19/20
Aurora Serverless for MySQL, ideal for infrequent access patterns with minimal downtime and allows you to provision
a MySQL instance without selecting a particular instance type.

## 20/20
point is create CloudFront origin group with two buckets, 1th is primary, 2th is secondary. then can implement failover handling for the primary and standby bucket.

